% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/core_bart.R
\name{core_bart}
\alias{core_bart}
\title{Run the BART algorithm for supervised learning with the basic CGM priors and Sparse option.}
\usage{
core_bart(
  y_train,
  X_train,
  X_test = NULL,
  alpha = 0.95,
  beta = 2,
  min_samples_leaf = 5,
  max_depth = 10,
  n_trees = 200,
  cutpoint_grid_size = 100,
  outcome_train = 1,
  nu = 4,
  lambda = 0.5,
  a_leaf = 2,
  b_leaf = NULL,
  a_forest = 1,
  b_forest = 1,
  num_burnin = 100,
  num_mcmc = 100,
  random_seed = -1,
  sample_sigma_global = TRUE,
  sample_sigma_leaf = TRUE,
  sparse = FALSE,
  alpha_dart = NULL,
  rho_dart = NULL,
  a_dart = 1,
  b_dart = 0.5,
  keep_burnin = FALSE
)
}
\arguments{
\item{y_train}{Outcome to be modeled by the ensemble.}

\item{X_train}{Covariates used to split trees in the ensemble. May be provided either as a dataframe or a matrix.
Matrix covariates will be assumed to be all numeric. Covariates passed as a dataframe will be
preprocessed based on the variable types (e.g. categorical columns stored as unordered factors will be one-hot encoded,
categorical columns stored as ordered factors will passed as integers to the core algorithm, along with the metadata
that the column is ordered categorical).}

\item{X_test}{(Optional) Test set of covariates used to define "out of sample" evaluation data.
May be provided either as a dataframe or a matrix, but the format of \code{X_test} must be consistent with
that of \code{X_train}.}

\item{alpha}{Prior probability of splitting for a tree of depth 0 in the mean model. Tree split prior combines \code{alpha_mean} and \code{beta_mean} via \code{alpha_mean*(1+node_depth)^-beta_mean}. Default: \code{0.95}.}

\item{beta}{Exponent that decreases split probabilities for nodes of depth > 0 in the mean model. Tree split prior combines \code{alpha_mean} and \code{beta_mean} via \code{alpha_mean*(1+node_depth)^-beta_mean}. Default: \code{2}.}

\item{min_samples_leaf}{Minimum allowable size of a leaf, in terms of training samples, in the mean model. Default: \code{5}.}

\item{max_depth}{Maximum depth of any tree in the ensemble in the mean model. Default: \code{10}. Can be overridden with \code{-1} which does not enforce any depth limits on trees.}

\item{n_trees}{Number of trees in the ensemble for the conditional mean model. Default: \code{200}. If \code{n_trees = 0}, the conditional mean will not be modeled using a forest, and the function will only proceed if \code{num_trees_variance > 0}.}

\item{cutpoint_grid_size}{Maximum size of the "grid" of potential cutpoints to consider. Default: \code{100}.}

\item{outcome_train}{}

\item{nu}{}

\item{lambda}{}

\item{a_leaf}{Shape parameter in the \code{IG(a_leaf, b_leaf)} leaf node parameter variance model. Default: \code{3}.}

\item{b_leaf}{Scale parameter in the \code{IG(a_leaf, b_leaf)} leaf node parameter variance model. Calibrated internally as \code{0.5/n_trees} if not set here.}

\item{a_forest}{}

\item{b_forest}{}

\item{num_burnin}{Number of "burn-in" iterations of the MCMC sampler. Default: 100.}

\item{num_mcmc}{Number of "retained" iterations of the MCMC sampler. Default: 100.}

\item{sample_sigma_global}{}

\item{sample_sigma_leaf}{}

\item{alpha_dart}{}

\item{rho_dart}{}

\item{a_dart}{}

\item{b_dart}{}
}
\value{
List of sampling outputs and a wrapper around the sampled forests
}
\description{
Run the BART algorithm for supervised learning with the basic CGM priors and Sparse option.
}
